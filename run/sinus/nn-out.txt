#
# Neural net output
#
# nLayers,nHiddenLayers,nSteps,nProblemSize,inpLength,outLength
4 2 3 141
# layer lengths
1 10 10 1
# activation function type, biases, weights
# step 1
# activation function type
Sigmoid
# biases
  -7.2383305047627982     
  -7.3724218102512964     
   12.375379151683369     
  -1.5027311896230378     
  -2.3018511564911250     
  -2.4868923378792287     
  0.71003767793456041     
  -1.0470842939046545     
  0.57778028792235681     
  -2.3951355821257709     
# weights
   10.544492446225700     
   15.231907636694920     
  -10.898621165648118     
  0.56374248605204158     
   10.384536416609421     
 -0.88672204928178111     
 -0.17745053667071048     
  -1.2179843786481623     
  -12.681769191310853     
  0.44721751465601506     
# step 2
# activation function type
Sigmoid
# biases
  -1.0672863696215014     
  0.44668685269840552     
 -0.24380759570995983     
  0.96674566660625871     
   1.7721320507386435     
  0.79367977819170976     
  0.60005617545607237     
  0.55142287548200031     
 -0.13960092790303524     
  -1.6768577063909704     
# weights
 -0.42514454211776143     
  0.76702694035508245     
  0.49468378059018597     
  0.57845173322347010     
  0.24308067204285574     
  0.49362854212971613     
  -1.1477573622828363     
 -0.26580076927791890     
 -0.73192663763976384     
 -0.91925590046627925     
  -2.2865231917318700E-002
  0.26094566206435471     
  0.10172820958400694     
 -0.67402901177727592     
  0.50456306781758720     
  0.39164280479358182     
  0.33278468049433901     
  0.12155940029981840     
  0.49599652552265366     
 -0.83984475284446558     
 -0.84983736528258114     
 -0.29311120340021496     
  -1.0062522455169498     
   2.7968269525685995E-002
 -0.75150039791132428     
  0.91808014713126873     
  0.45178818514866803     
  0.83575842107269749     
  0.98428130323180163     
  -7.7620621277081150E-002
  -4.5088166678316259     
   4.6961613893155594     
 -0.17236400447855449     
  0.62440549663368639     
  -3.8013265569617856     
 -0.67915236060338835     
  0.93137300817403268     
  0.67458041430053095     
  -2.0588730558289821     
  0.75803739252463376     
  -1.8621647205020198     
   1.0749013071272580     
 -0.36497051656355189     
 -0.70190340089653758     
  -1.2223913736078085     
  0.54317827770791749     
  0.25907878457745992     
  0.18089082510937102     
  -2.6380500028766449     
  0.34315004959625567     
 -0.67416503673305839     
  0.11679641699041003     
 -0.26991922833393056     
   1.1704395954771244E-002
  -1.0227856713476833     
  -9.9903180572023714E-002
  0.74703346912865431     
 -0.65447639859832696     
  -1.7803419915412793     
  -1.0168121403636512     
  0.25123132614180926     
 -0.37551718909268400     
 -0.81401150813062317     
 -0.24751960969182046     
 -0.31999390577958758     
  0.29361716363791079     
 -0.94945430578001977     
 -0.39043532239382100     
   1.9803831887427152     
  0.68301824985757698     
  0.13568906481689696     
  0.39869962486538318     
 -0.59882111620511180     
 -0.86033152144347957     
 -0.59667310182745947     
  -5.4057231441194294E-002
 -0.68946153491154416     
  0.32260201475104394     
  0.27454017784659424     
  -1.1264557884744437     
  -1.2011856660971711     
  0.52484575871456085     
  0.21759134177586406     
 -0.77923210481614902     
 -0.13669051117354453     
  0.87749935979707683     
 -0.89477595381325070     
  0.43164911235754333     
  0.22545861849491330     
  0.54473607714959005     
  0.38854622547599027     
   9.7693708680920874     
  -7.2573705974428586     
   6.1801534057221608E-002
 -0.85571095667668473     
  0.37362947888863635     
  -1.4063395972159312     
 -0.87719056867769907     
 -0.72662685971274954     
  0.14786364104293992     
# step 3
# activation function type
Identity
# biases
  -2.5807801741109149     
# weights
 -0.15318483410017439     
  -1.0055339628066196     
 -0.71875851438777305     
   5.5279922720636723     
   3.1803171583611776     
   2.0276445032110701     
  -1.9126624161558501     
 -0.35909274265459140     
 -0.14856896852310569     
   7.7623751277450026     
# L2 norm of training data
   3.8708984127344692E-004
