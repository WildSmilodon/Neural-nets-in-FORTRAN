#
# Neural net output
#
# nLayers,nHiddenLayers,nSteps,nProblemSize,inpLength,outLength
4 2 3 141
# layer lengths
1 10 10 1
# activation function type, biases, weights
# step 1
# activation function type
Sigmoid
# biases
 -0.21430158831722701     
  0.34344401790303503     
 -0.67396060316136974     
  -2.6413705386127888     
  -1.4635894099318747     
  0.84596725861410904     
  0.53016243880169789     
   1.3720106476486169     
   1.7292794263908773     
  0.48846286577770420     
# weights
  0.31861349355613605     
   1.4612231303226322     
  0.26518437115517041     
   2.9021964434444554     
  0.68836354390887688     
 -0.21273408839302002     
  0.31609432612774452     
 -0.79002558131883072     
  -1.1490811235067193     
   1.5428832397672552     
# step 2
# activation function type
Sigmoid
# biases
  0.62159851215205320     
 -0.54758478354651841     
 -0.48008875730248934     
   1.1708165520323737     
  0.23571736667891668     
 -0.29481827519261022     
   9.9815866767166819E-002
 -0.35844035018668213     
 -0.39554243908444864     
 -0.47223193824206089     
# weights
  0.80990890605826615     
 -0.55981872905719143     
 -0.48025455612211981     
  0.32784386501245349     
  0.85005963109186577     
 -0.20482946580701644     
 -0.72293837059023724     
  0.34535520561133970     
   1.0559545573657552     
 -0.52474157411941269     
 -0.92137597764188828     
  -7.0579101535237360E-002
  0.19229192984490159     
  0.44210411421119455     
  0.75301124761970806     
  0.77504639667497410     
 -0.88319056671806728     
  0.29622572037474237     
 -0.39211362368536257     
 -0.91318654259594956     
  0.40295571629986687     
  0.26719317903857764     
 -0.89524705937627502     
   2.5604371267742950E-002
 -0.81084061382632278     
 -0.28994079170998793     
  0.82791380763535138     
  0.63767520850776949     
  0.41314586167682771     
 -0.92188964167193599     
 -0.76860128183462406     
  0.71690998931636629     
  -4.7086386240863129E-002
 -0.89567786913413328     
 -0.86070888279416380     
 -0.48550357020098589     
 -0.58818487116013762     
   1.2538491348897791     
  0.11710436878424460     
  -6.8888978370805140E-002
  0.56611112262676111     
 -0.60342212666064576     
  0.33115437578682638     
  -1.1212295623982313     
 -0.83794229640597884     
  0.40630409291153491     
 -0.17153017861326858     
  0.52072800695611154     
   1.2778291221243241     
  0.11055687453066183     
  0.65768529753029126     
 -0.92805995241346340     
  0.58028138680786612     
  0.65674551207735332     
   1.0189187729169897     
 -0.63271912336949809     
  0.58809792596115740     
 -0.77133644764249576     
 -0.11576644847591690     
 -0.59223247383887889     
  -3.8164758075315421E-002
 -0.51651651738684368     
  0.89907887083580673     
 -0.56658454492792631     
 -0.56634959243602490     
 -0.92442233192058498     
  0.30511220726173921     
  0.30598373057449307     
 -0.27648236362033679     
 -0.51370863222812491     
 -0.91470952418100870     
 -0.27720878807032517     
  0.42435322193511749     
 -0.62314658140717849     
  0.85901313589569961     
  0.13943934092341762     
  0.17807961937947073     
  0.59516701743243028     
  0.79782134932359783     
 -0.58394917403106994     
 -0.88163650825683726     
  -8.8874498982301528E-002
  0.29775278725313420     
 -0.58676158682638413     
 -0.64162807640864028     
  -5.0867458892080102E-002
   5.8556305200519985E-002
 -0.96478191468053254     
  0.23136087101734168     
  0.78194302261801663     
 -0.52755773832756936     
  0.67705765674640728     
  0.74564722940800610     
 -0.39491336268291710     
   6.7724241443565078E-002
  0.60026618219306571     
 -0.77972893847666547     
 -0.19285014895386773     
  0.49932135418104590     
  0.93643179846473767     
# step 3
# activation function type
Identity
# biases
 -0.63568132974573621     
# weights
  0.16292546716055434     
 -0.94343613857496023     
  -3.2983537505360191E-002
   1.1349459709207135     
   1.0519572399241119     
  -1.0659407533770431     
 -0.32136737328669679     
  0.28919909846528097     
  0.76356905348940585     
 -0.17597652290094312     
# L2 norm of training data
   4.0457056799154377E-006
